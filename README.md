Contrastive Predictive Coding (CPC) offers a novel approach to interpret audio data through self-supervised learning, diverging from traditional supervised techniques reliant on labeled data. In this project, we delve into the application of CPC in real-time audio processing, where labeled annotations are often scarce or costly to obtain. By harnessing the inherent structure and correlations within unlabeled audio data, CPC learns to extract meaningful representations through an autoregressive model coupled with an encoder. The core objective of CPC is to derive generic features capturing the fundamental characteristics of audio inputs, rather than optimizing for specific tasks such as speaker identification or speech recognition. Leveraging the learned representations, our framework explores the potential for enhancing performance across various audio processing tasks. By training the model without explicit human-labeled annotations, we demonstrate the effectiveness of self-supervised learning in extracting relevant features from audio signals.![image](https://github.com/user-attachments/assets/997cf120-c15d-436d-9b84-ab680b6d1ee6)
